{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install open3d"
      ],
      "metadata": {
        "id": "fDQwL6M18E44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import Compose, ToTensor\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import random\n",
        "from random import sample\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import open3d as o3d\n",
        "# to make more deterministic the task\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "JVhkM1VPnSNC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### PARAMS\n",
        "INPUT_EXTENTION = \".ply\"\n",
        "ROOT_FOLDER = os.path.dirname(\"/content/drive/MyDrive/Output_ROTATED_v7/\")"
      ],
      "metadata": {
        "id": "mB0_tbQJKxe8"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svujEdQ9X5Cq",
        "outputId": "a30caf97-c7f2-4e68-e5d4-ffb7f3dc12a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGaa9su4nBTA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip '/content/drive/MyDrive/Output_ROTATED_v7.zip' -d \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "bGezTPQWgWEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = [dir for dir in sorted(os.listdir(ROOT_FOLDER)) if os.path.isdir(os.path.join(ROOT_FOLDER,dir))]\n",
        "print(folders)\n",
        "classes = {folder:i for i, folder in enumerate(folders)};\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBNg3DeNrrKV",
        "outputId": "fa923bcf-d6cb-4862-98b7-1fd3715f0ed1"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bathtub': 0,\n",
              " 'bed': 1,\n",
              " 'chair': 2,\n",
              " 'desk': 3,\n",
              " 'dresser': 4,\n",
              " 'monitor': 5,\n",
              " 'night_stand': 6,\n",
              " 'sofa': 7,\n",
              " 'table': 8,\n",
              " 'toilet': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_voxelGrid(filename):\n",
        "    if os.path.isfile(filename) and os.path.join(filename).endswith(INPUT_EXTENTION):\n",
        "      voxelGrid = o3d.io.read_voxel_grid(filename, format='auto', print_progress=True)\n",
        "      np_voxels = np.array(list(map(lambda x: x.grid_index, voxelGrid.get_voxels())))\n",
        "      #print(len(np_voxels))\n",
        "\n",
        "      np_voxelGrid = np.zeros((32, 32, 32))\n",
        "      for j in range(len(np_voxels)):\n",
        "        x = np_voxels[j][0]\n",
        "        y = np_voxels[j][1]\n",
        "        z = np_voxels[j][2]\n",
        "        np_voxelGrid[x,y,x] = 1\n",
        "        #print(np_voxelGrid)\n",
        "      \n",
        "      #print(np_voxelGrid.shape)\n",
        "      return np_voxelGrid\n",
        "    else: raise('Not a valid PLY file, is the location correct?')"
      ],
      "metadata": {
        "id": "qTupq6fQufC7"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VoxelGridDataset(Dataset):\n",
        "    def __init__(self, dataset_folder, folder=\"train\", transform=None):\n",
        "        self.dataset_folder = dataset_folder\n",
        "        folders = [dir for dir in sorted(os.listdir(dataset_folder)) if os.path.isdir(dataset_folder+\"/\"+dir)]\n",
        "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
        "        self.transforms = transform\n",
        "        self.files = []\n",
        "        for category in classes.keys():\n",
        "          model_folder = os.path.join(dataset_folder,category,folder)\n",
        "          for file in os.listdir(model_folder):\n",
        "            if file.endswith(INPUT_EXTENTION):\n",
        "              sample = {}\n",
        "              sample['path'] = os.path.join(model_folder,file)\n",
        "              sample['category'] = category\n",
        "              self.files.append(sample)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __preproc__(self, file):\n",
        "        voxelGrid = read_voxelGrid(file)\n",
        "        if self.transforms:\n",
        "            voxelGrid = self.transforms(voxelGrid)\n",
        "\n",
        "        return voxelGrid\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.files[idx]['path']\n",
        "        #print(path)\n",
        "        category = self.files[idx]['category']\n",
        "        voxelGrid = self.__preproc__(path)\n",
        "        cat = [0 for _ in range(10)]\n",
        "        cat[self.classes[category]] = 1\n",
        "        x_cat = torch.tensor(cat)\n",
        "        # return {'voxelGrid': voxelGrid, 'category': tuple(cat)}\n",
        "        return voxelGrid, x_cat"
      ],
      "metadata": {
        "id": "TqEAph3Unl7X"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder = ROOT_FOLDER\n",
        "folders = [dir for dir in sorted(os.listdir(dataset_folder)) if os.path.isdir(dataset_folder+\"/\"+dir)]\n",
        "print(folders)\n",
        "folder = \"train\"\n",
        "files = []\n",
        "for category in classes.keys():\n",
        "  model_folder = os.path.join(dataset_folder,category,folder)\n",
        "  for file in os.listdir(model_folder):\n",
        "    if file.endswith(INPUT_EXTENTION):\n",
        "      #print(model_folder+\"/\"+file)\n",
        "      files.append(file)\n",
        "print(len(files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn8oLkcRWHNu",
        "outputId": "2aa25190-4237-4370-cc13-3604f234c657"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
            "9986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = Compose([\n",
        "    ToTensor(), #this converts numpy or image to torch tensor and normalizes it in 0, 1\n",
        "])\n",
        "\n",
        "train_dataset =  VoxelGridDataset(ROOT_FOLDER, \"train\", transforms)\n",
        "test_dataset =  VoxelGridDataset(ROOT_FOLDER, \"test\", ToTensor())\n",
        "\n",
        "#valid_dataset =  VoxelGridDataset(ROOT_FOLDER, \"valid\", ToTensor())"
      ],
      "metadata": {
        "id": "50tkzgGQnoqv"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train dataset size: ', len(train_dataset))\n",
        "print('Test dataset size: ', len(test_dataset))\n",
        "print('Number of classes: ', len(train_dataset.classes))\n",
        "print('Sample VoxelGrid shape: ', train_dataset)\n",
        "print('Class: ', train_dataset[0])\n",
        "# print('Class: ', train_dataset[1000]['category'])\n",
        "# print('Class: ', train_dataset[8000]['category'])\n",
        "# print('Class: ', train_dataset[8900]['category'])\n",
        "# print('Class: ', train_dataset[9900]['category'])\n",
        "# folders[train_dataset[9900]['category'].index(1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrGv_AY7YlIO",
        "outputId": "e45610b4-fe4f-43c7-9ceb-29f6a8e1c0c1"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size:  9986\n",
            "Test dataset size:  2724\n",
            "Number of classes:  10\n",
            "Sample VoxelGrid shape:  <__main__.VoxelGridDataset object at 0x7f8d62915a60>\n",
            "Class:  (tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "nw=os.cpu_count()\n",
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=nw)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=nw)\n",
        "\n",
        "#valid_dataloader = DataLoader(valid_dataset, batch_size, shuffle=False, num_workers=nw)"
      ],
      "metadata": {
        "id": "rNrdE3a5vGjw"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getDimCNN(W,K,P,S):\n",
        "  \"\"\"[(W−K+2P)/S]+1.\n",
        "    W is the input volume\n",
        "    K is the Kernel size\n",
        "    P is the padding\n",
        "    S is the stride\"\"\"\n",
        "  n = ((W-K+2*P)/S)+1\n",
        "  return n"
      ],
      "metadata": {
        "id": "ztDKUJ12vjrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(getDimCNN(32,3,1,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpSrsQMhvlRb",
        "outputId": "0d9e1e44-2416-462f-b886-8bae82b61cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeAuq2BatZkl"
      },
      "outputs": [],
      "source": [
        "def cutout_3d(volume, cutout_size=(8,8,8)):\n",
        "    # Shape is 32x32x32\n",
        "    x = np.random.randint(0, 32 - cutout_size[0])\n",
        "    y = np.random.randint(0, 32 - cutout_size[1])\n",
        "    z = np.random.randint(0, 32 - cutout_size[2])\n",
        "    cutout_cube = (x, y, z, cutout_size[0], cutout_size[1], cutout_size[2])\n",
        "    volume[x:x+cutout_size[0], y:y+cutout_size[1], z:z+cutout_size[2]] = 0\n",
        "    return volume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kaYf4IZULYA"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "X_validation, y_validation = prepare_data(test[1], \"test\")\n",
        "y_validation = to_categorical(y_validation, 10) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmlNdQPruk1K"
      },
      "outputs": [],
      "source": [
        "idt = np.random.permutation(len(X_validation))\n",
        "X_validation, y_validation = X_validation[idt], y_validation[idt]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HERE"
      ],
      "metadata": {
        "id": "31whMzYZ2eBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module, Sequential, Conv2d, BatchNorm2d, ReLU"
      ],
      "metadata": {
        "id": "eghwJnGDv8I7"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from torch.nn.modules.dropout import Dropout\n",
        "from torch.nn import Module, Linear, Sequential, Conv3d, BatchNorm3d, ReLU, MaxPool3d, Dropout, Dropout3d\n",
        "\n",
        "class VGNet(Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        kernel_size = 3\n",
        "        padding_val = kernel_size // 2\n",
        "\n",
        "        self.network = Sequential(\n",
        "            # OPT B: -> CONV/FC -> ReLu(or other activation) -> Dropout -> BatchNorm -> CONV/FC\n",
        "            # Block 1 : > CONV -> BatchNorm -> ReLu -> Dropout ->\n",
        "            Conv3d(1, 16, kernel_size=3, stride=1, padding=padding_val), #32-->16 (if s=2)\n",
        "            BatchNorm3d(16),\n",
        "            ReLU(),\n",
        "            Dropout(0.2),\n",
        "            MaxPool3d(kernel_size=3, stride=2), # H/3 -->\n",
        "\n",
        "            # Block 2 : > CONV -> BatchNorm -> ReLu -> Dropout ->\n",
        "            Conv3d(16, 32, kernel_size=3, stride=1, padding=padding_val), #32-->16 (if s=2)\n",
        "            BatchNorm3d(32),\n",
        "            ReLU(),\n",
        "            Dropout(0.2),\n",
        "            MaxPool3d(kernel_size=3, stride=2), # H/3\n",
        "\n",
        "            # Block 3 : > CONV -> BatchNorm -> ReLu -> Dropout ->\n",
        "            Conv3d(32, 64, kernel_size=3, stride=2, padding=padding_val), #32-->16 (if s=2)\n",
        "            BatchNorm3d(64),\n",
        "            ReLU(),\n",
        "            Dropout(0.2),\n",
        "            MaxPool3d(kernel_size=3, stride=2), # H/3\n",
        "        )\n",
        "        self.classification_layer = Linear(64, 10) #1124864 | 1728\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv3d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print((x.shape))\n",
        "        y = self.network(x).reshape((x.shape[0], -1))\n",
        "        #print(y.shape)\n",
        "        y = self.classification_layer(y)\n",
        "        return y"
      ],
      "metadata": {
        "id": "Bo0pcYl2vvyX"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQ-aMtJVtx4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0KftTh7V89rQ",
        "outputId": "8e3c7c81-b48a-47b7-e085-7475bd9afa24"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "network = VGNet()\n",
        "network.to(device)\n",
        "# print(np.random.rand(1,3,5,5))\n",
        "# summary(network, (1,32,32,32))\n",
        "# print(network)\n",
        "temp = torch.rand(1,1,32,32,32)\n",
        "print(network(temp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Wi9DatxZFr",
        "outputId": "b0239d15-bf20-455d-a749-c944ba2ed88b"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4.5546,  1.2692,  0.1168,  3.6142,  2.3000,  2.5117, -1.1824,  1.0298,\n",
            "          1.8317,  0.0252]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from tqdm import tqdm\n",
        "model = VGNet()\n",
        "opt = SGD(model.parameters(), lr=1e-2, weight_decay = 0)\n",
        "loss_fn = BCEWithLogitsLoss()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "epochs=10\n",
        "best_val = np.inf\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    print(f\"Epoch: {epoch+1}\")\n",
        "    iterator = tqdm(train_dataloader)\n",
        "    for batch_x, batch_y in iterator:\n",
        "        #print(batch_x,batch_y)\n",
        "        # batch_x = batch_x[None, :]\n",
        "        batch_x = torch.unsqueeze(batch_x, dim=1)\n",
        "        batch_x = batch_x.float()\n",
        "\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        y_pred = model(batch_x)\n",
        "\n",
        "        loss = loss_fn(y_pred, batch_y.float())\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        iterator.set_description(f\"Train loss: {loss.detach().cpu().numpy()}\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = []\n",
        "        true = []\n",
        "        for batch_x, batch_y in tqdm(valid_dataloader):\n",
        "            \n",
        "            batch_x.reshape(1,...)\n",
        "            batch_x = batch_x.float()\n",
        "            batch_y = batch_y.float()\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            y_pred = model(batch_x)\n",
        "\n",
        "            predictions.append(y_pred)\n",
        "            true.append(batch_y)\n",
        "        predictions = torch.cat(predictions, axis=0)\n",
        "        true = torch.cat(true, axis=0)\n",
        "        val_loss = loss_fn(predictions, true)\n",
        "        val_acc = (torch.sigmoid(predictions).round() == true).float().mean()\n",
        "        print(f\"loss: {val_loss}, accuracy: {val_acc}\")\n",
        "    \n",
        "    if val_loss < best_val:\n",
        "        print(\"Saved Model\")\n",
        "        torch.save(model.state_dict(), \"model.pt\")\n",
        "        best_val = val_loss\n",
        "        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "UwhIuJRvtanx",
        "outputId": "07cda1a6-c47b-470d-80d9-42d9c195e816"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/157 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 32, 32, 32])\n",
            "torch.Size([64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 1.9977413415908813:   1%|          | 1/157 [00:08<22:21,  8.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 32, 32, 32])\n",
            "torch.Size([64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.9996289014816284:   1%|▏         | 2/157 [00:11<13:21,  5.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 32, 32, 32])\n",
            "torch.Size([64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.6572760343551636:   2%|▏         | 3/157 [00:13<10:09,  3.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 32, 32, 32])\n",
            "torch.Size([64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.5196121335029602:   3%|▎         | 4/157 [00:16<08:43,  3.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 32, 32, 32])\n",
            "torch.Size([64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.4601217806339264:   3%|▎         | 5/157 [00:20<09:02,  3.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 32, 32, 32])\n",
            "torch.Size([64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain loss: 0.4601217806339264:   3%|▎         | 5/157 [00:23<12:07,  4.79s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-236-72bf280d2be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train loss: {loss.detach().cpu().numpy()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "cO0v3u39HQj9",
        "outputId": "778a7b98-6eb9-4cee-a9a4-d4ee4b8b2745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 32, 32, 32])\n",
            "torch.Size([1, 32, 32, 32])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-09048d269066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-38fa46f78166>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# exponential_average_factor is set to self.momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36m_check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected 5D input (got {}D input)\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected 5D input (got 4D input)"
          ]
        }
      ],
      "source": [
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "TOT_MODELS = 2\n",
        "\n",
        "Histories = []\n",
        "model_ = np.empty(TOT_MODELS, dtype=object)\n",
        "#Repeat 5 times\n",
        "for i in range(TOT_MODELS):\n",
        "  #Compile the model\n",
        "  model_[i] = VGNet()\n",
        "  criterion = CrossEntropyLoss()\n",
        "  optimizer = SGD(model_[i].parameters(), lr=0.01)\n",
        "  patience = 10\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(30):\n",
        "      # Train\n",
        "      model_[i].train()\n",
        "      train_loss = 0.0\n",
        "      #X_train_tensor = torch.from_numpy(X_train).float()\n",
        "\n",
        "      for inputs, labels in zip(X_train_tensor, y_train_tensor):\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          # print(inputs.shape)\n",
        "          # inputs.reshape(1, 1, 32, 32, 32)\n",
        "          # print(inputs.shape)\n",
        "          outputs = model_[i](inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_loss += loss.item()\n",
        "      train_losses.append(train_loss / len(X_train))\n",
        "\n",
        "      # Validate\n",
        "      model_[i].eval()\n",
        "      val_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      with torch.no_grad():\n",
        "          for inputs, labels in zip(X_validation, y_validation):\n",
        "              inputs = inputs.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "              outputs = model_[i](inputs)\n",
        "              print(\"OUTPUTS\" + str(outputs.shape))\n",
        "              loss = criterion(outputs, labels)\n",
        "              val_loss += loss.item()\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "      val_loss /= len(X_validation)\n",
        "      val_losses.append(val_loss)\n",
        "      acc = 100. * correct / total\n",
        "      if acc > best_acc:\n",
        "          counter = 0\n",
        "          best_acc = acc\n",
        "          torch.save(model_[i].state_dict(), 'best_model.pth')\n",
        "          #early_stop.best = acc\n",
        "      else:\n",
        "        counter = counter + 1\n",
        "      if counter >= patience:\n",
        "          print(\"Early stopping\")\n",
        "          break\n",
        "\n",
        "      print(\"Early Stop called or End of Epochs reaches: Saving the model\")\n",
        "      #Save the model\n",
        "      model_name = \"Model\" + str(i) + \".pth\"\n",
        "      os.rename(\"best_model.h5\", model_name)\n",
        "      #Histories.append(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V7Lmandt5v3"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "  score = model_[i].evaluate(X_validation,y_validation)\n",
        "  print(\"The score of Model \" + str(i) + \" is\")\n",
        "  print(score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_O8dHVZnELv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#plot the train/validation loss and accuracy\n",
        "def plot_graphs(history, metric):\n",
        "    \n",
        "    plt.plot(history.history[metric])\n",
        "    plt.plot(history.history['val_'+metric], '')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([metric, 'val_'+metric])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(Histories[0], 'accuracy')\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(Histories[0], 'loss')"
      ]
    }
  ]
}