import torch
import torch.nn as nn

class standardModel(nn.Module):
    def __init__(self, num_classes):
        super(standardModel, self).__init__()
        
        # Define the convolutional layers
        self.conv1 = nn.Conv3d(32, 64, kernel_size=(3,3,3), stride=1, padding=0)
        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3,3,3), stride=1, padding=0)
        self.conv3 = nn.Conv3d(128, 256, kernel_size=(3,3,3), stride=1, padding=0)
        
        # Define the pooling layers
        self.pool = nn.MaxPool3d(kernel_size=(2,2,2), stride=2)
        
        # Define the fully-connected layers
        self.fc1 = nn.Linear(256, 128)
        self.fc2 = nn.Linear(128, num_classes)
        
        # Define the activation functions
        self.relu = nn.ReLU()
        self.softmax = nn.Softmax(dim=1)
        
    def forward(self, model):
        # Apply the convolutional layers
        model = self.relu(self.conv1(model))
        model = self.relu(self.conv2(model))
        model = self.relu(self.conv3(model))
        
        # Apply the pooling layers
        model = self.pool(model)
        
        # Flatten the output of the pooling layers
        model = model.view(model.size(0), -1)
        
        # Apply the fully-connected layers
        model = self.relu(self.fc1(model))
        model = self.fc2(model)
        
        # Apply the softmax function
        model = self.softmax(model)
        
        return model
