% !TEX root = template.tex

\section{Introduction}
\label{sec:introduction}

The 3D Object recognition task contributes to the field of computer vision by enabling the detection, classification and also localization of three-dimensional objects in images or video streams. Thanks to the improvements in Computer Vision and Deep Learning technologies these tasks are more and more reliable and accessible, enabling many emerging applications like augmented reality, virtual reality and many more related to robotics interactions with the environment. 
The way 3D data is represented has a significant impact on the performance of the 3D object detection. Here we introduce two of the most common representation for 3D Objects.
\begin{itemize}
    \item The Point-based representation uses a set of 3D points to describe the geometry of an object. This representation is lightweight and can handle large point clouds efficiently. The structure can  retain precise point positions, but at the same time it has a limited feature representation and since the points are unordered using them requires a high computational capacity \cite{liu2019pointvoxel}.

    \item Voxel-based representation models the object as a 3D grid of voxels, where each voxel has a binary value to indicate whether the object occupies it or not. This representation provides detailed information about the shape and structure of objects, but it requires a lot of memory, since we have to store also the empty blocks, therefore they are not scalable as other approaches \cite{liu2019pointvoxel}.
\end{itemize}

In this paper, we propose a "label predictor" that relies on 5 models using an ensembling technique to classify 3D objects, using at the same time a coarse voxel granularity. 
As mentioned above, the Voxel Grid structure maintains information regarding the shape and structure of the 3D Object, in order to properly capture and maximize the spatial relationship provided by the Voxel-Grid structure, we decided to use \ac{CNN}s as core networks. 

The main advantages of using this kind of approach is that each weak model is trained on a portion of the dataset, requiring smaller and thus quicker models. Since the weak models are trained on different portion of the dataset, they learn and make prediction based on different features, increasing the generalization of our ensemble system. If one can run all 5 weak models in parallel, and then choose the final label, this may result faster than running a single bigger model.

The memory requirements for voxelized 3D objects increase cubically with the resolution. We have seen that, for a resolution of 16, where each object is divided in a 16x16x16 voxel grid, the visualization is too coarse to be used. On the other hand, a resolution of 64 requires 262.400 blocks for each object, which is too much considering our memory capacity. In the end, we went with the resolution of 32x32x32, which has an affordable amount of blocks per objects ($\sim$32.000) \cite{liu2019pointvoxel}. In our case, this resolution is the optimal trade-off between memory and information loss. The expectation is that using a restrained number of blocks for each Object, the model will be more efficient by taking less time to execute and requiring less memory to storage all the Voxels information. 

The dataset which we used for training our models is a modified version of the ModelNet10 \cite{7298801}. The initial dataset is composed by 4899 aligned 3D CAD model divided in 10 different classes, we perform data augmentation to create a portion of rotated entries, which is useful to make our models learn how to classify objects independently of their rotation in the Z axis. 

The rest of the paper is organized as follows: Section \ref{sec:related_work} provides an overview of related works; Section \ref{sec:pipeline} describes our approach; In Section \ref{sec:dataset} we describe in details the dataset and pre-processing techniques; In Section \ref{sec:learning_framework} we present the Convolutional Neural Network that we built, summarizing the parameters we choose; In Section \ref{sec:results} we discussed our main findings; finally, Section \ref{sec:conclusions} draws some conclusions and outlooks for future works.\\
